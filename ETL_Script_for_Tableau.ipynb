{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07748bfa",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "libraries"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import undetected_chromedriver as uc\n",
    "import sqlite3\n",
    "import schedule\n",
    "import time\n",
    "import os\n",
    "import subprocess\n",
    "import psutil\n",
    "import datetime\n",
    "import msoffcrypto\n",
    "from io import BytesIO\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd9fc16",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Preprocess function"
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b3216d",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "loading raw data"
   },
   "outputs": [],
   "source": [
    "    DB_path = r\"Y:\\Melanox\\stations\\Rovner\\KRIOT_V4_1_.xlsm\"\n",
    "    df = pd.read_excel(DB_path, sheet_name=\"Closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9296e1",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Validation DB"
   },
   "outputs": [],
   "source": [
    "    print(df.head())\n",
    "    print(\"----------\")\n",
    "    print(\"Columns:\", df.columns)\n",
    "    print(\"----------\")\n",
    "    print(\"Data Types:\\n\", df.dtypes)\n",
    "    print(\"----------\")\n",
    "    print(\"Summary:\\n\", df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c46fc1",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Standartize columns names"
   },
   "outputs": [],
   "source": [
    "    df.columns = df.columns.str.strip()\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace(\" \", \"_\")\n",
    "\n",
    "    print(\"----------\")\n",
    "    print(\"Updated Columns:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56deb53",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Convert 'current_time' to datetime format"
   },
   "outputs": [],
   "source": [
    "    df['current_time'] = pd.to_datetime(df['current_time'], format='%Y-%m-%d %H:%M', errors='coerce')\n",
    "    df['start_time'] = pd.to_datetime(df['start_time'], format='%Y-%m-%d %H:%M', errors='coerce')\n",
    "    df['end_time'] = pd.to_datetime(df['end_time'], format='%Y-%m-%d %H:%M', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6351f5ee",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Looking for rows where time cells have non-time values"
   },
   "outputs": [],
   "source": [
    "    invalid_rows = df[~df['technician_sr_time'].astype(str).str.match(r'^\\d{1,2}:\\d{2}:\\d{2}$', na=True) |\n",
    "                          ~df['ticket_lifetime'].astype(str).str.match(r'^\\d{1,2}:\\d{2}:\\d{2}$', na=True)]\n",
    "    print(\"Invalid rows found:\", invalid_rows.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17524e97",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Dropping rows where values and format is incorrect"
   },
   "outputs": [],
   "source": [
    "    df = df[df['technician_sr_time'].astype(str).str.match(r'^\\d{1,2}:\\d{2}:\\d{2}$', na=True) &\n",
    "            df['ticket_lifetime'].astype(str).str.match(r'^\\d{1,2}:\\d{2}:\\d{2}$', na=True)]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(\"Cleaned dataset size:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae1a99a",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Convert to timedelta format"
   },
   "outputs": [],
   "source": [
    "    df['technician_sr_time'] = pd.to_timedelta(df['technician_sr_time'])\n",
    "    df['ticket_lifetime'] = pd.to_timedelta(df['ticket_lifetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9fb67b",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Verify conversion"
   },
   "outputs": [],
   "source": [
    "    print(df[['technician_sr_time', 'ticket_lifetime', 'current_time', 'start_time', 'end_time']].head())\n",
    "    print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8292a2",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Clean Irrelevant rows Based on 'comment' column"
   },
   "outputs": [],
   "source": [
    "    unwanted_comments = ['duplicate', 'duplicates', 'dublicate', 'another shift replaced tb3905, station work properly', 'not needed', 'not relevant', 'no relevant', 'not actual', 'no actual', 'eror', 'error', 'Closed by S. Chebaniuk due to programm error', 'Test ticket', 'Test']\n",
    "    df['comment'] = df['comment'].astype(str).str.lower()\n",
    "    df = df[~df['comment'].isin(unwanted_comments)]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    print(\"----------\")\n",
    "    print(\"Rows after removing unwanted comments:\",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d521d560",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Replacing time value in 'technician_sr_time' if 'open_technician' and 'close_technician' is different"
   },
   "outputs": [],
   "source": [
    "    correction_time = pd.Timedelta(minutes=30)\n",
    "    df.loc[df['open_technician'] != df['close_technician'],'technician_sr_time'] = correction_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9582c6bc",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Define and Filtering the long ticket threshold"
   },
   "outputs": [],
   "source": [
    "    long_ticket_threshold = pd.Timedelta(hours=1, minutes=30)\n",
    "    long_tickets_df = df[df['technician_sr_time'] > long_ticket_threshold]\n",
    "    print(\"-----------\")\n",
    "    print(long_tickets_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ff5821",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Group data per technician and calculate total tickets"
   },
   "outputs": [],
   "source": [
    "    technician_stats = df.groupby('close_technician').agg(\n",
    "        ticket_qty = ('cause_of_failure', 'count'),\n",
    "        avg_ticket_time = ('technician_sr_time', 'mean')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918f5c3d",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Grouping long tickets by technician"
   },
   "outputs": [],
   "source": [
    "    long_ticket_stats = long_tickets_df.groupby('close_technician').agg(\n",
    "        long_tickets_qty = ('cause_of_failure', 'count')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aef627",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Merge the data"
   },
   "outputs": [],
   "source": [
    "    technician_stats = technician_stats.merge(long_ticket_stats, on='close_technician', how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1aa8927",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Conversion avg_ticket_time from timedelta to minutes for readability"
   },
   "outputs": [],
   "source": [
    "    technician_stats['avg_ticket_time'] = technician_stats['avg_ticket_time'].dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf421eb",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Calculate share of long tickets"
   },
   "outputs": [],
   "source": [
    "    technician_stats['long_ticket_percentage'] = (technician_stats['long_tickets_qty'] / technician_stats['ticket_qty']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaaae4c",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Display the results"
   },
   "outputs": [],
   "source": [
    "    print(\"----------\")\n",
    "    print(technician_stats.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb405da",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Overall ticket counts"
   },
   "outputs": [],
   "source": [
    "    total_tickets = df.shape[0]\n",
    "    total_long_tickets = long_tickets_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14b0eaa",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Overall percentage of long tickets"
   },
   "outputs": [],
   "source": [
    "    long_ticket_overall_percentage = (total_long_tickets / total_tickets) * 100\n",
    "    print(\"----------\")\n",
    "    print(\"Total Tickets:\", total_tickets)\n",
    "    print(\"Total Long Tickets (>1:30):\", total_long_tickets)\n",
    "    print(\"Overall Percentage of Long Tickets:\", long_ticket_overall_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05aa48e7",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Defining and removing the duplicate values across 'close_technician' column"
   },
   "outputs": [],
   "source": [
    "    unique_open_techs = df['open_technician'].unique()\n",
    "    unique_close_techs = df['close_technician'].unique()\n",
    "    print(\"----------\")\n",
    "    print(\"Unique Open Technician IDs:\", unique_open_techs)\n",
    "    print(\"----------\")\n",
    "    print(\"Unique Close Technician IDs:\", unique_close_techs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5600cf5e",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Dictionary of incorrect names mapped to correct ones"
   },
   "outputs": [],
   "source": [
    "    corrections = {\n",
    "        \"Alexey Bondorenko\": \"Alexey Bondarenko\",\n",
    "        \"Alexei Bondorenko\": \"Alexey Bondarenko\",\n",
    "        \"Gershon\": \"Gershon Yastrebov\",\n",
    "        \"Gershen Yastrebov\": \"Gershon Yastrebov\",\n",
    "        \"Andrey \": \"Andrey Sobolev\",\n",
    "        \"Josef Kon\": \"Joseph Kohn\",\n",
    "    }\n",
    "    df['open_technician'] = df['open_technician'].replace(corrections)\n",
    "    df['close_technician'] = df['close_technician'].replace(corrections)\n",
    "    print(\"----------\")\n",
    "    print(\"Updated Open Technician IDs:\", df['open_technician'].unique())\n",
    "    print(\"----------\")\n",
    "    print(\"Updated Close Technician IDs:\", df['close_technician'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05417cf2",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Replace empty cells with None values"
   },
   "outputs": [],
   "source": [
    "    df[['pl', 'sfg/top/retest']] = df[['pl', 'sfg/top/retest']].fillna(\"None\")\n",
    "    print(\"----------\")\n",
    "    print(df[['pl', 'sfg/top/retest']].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caab15cf",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Define time window and range"
   },
   "outputs": [],
   "source": [
    "    start_date = pd.to_datetime(\"2025-04-25\")\n",
    "    end_date = pd.to_datetime(datetime.datetime.today().date())\n",
    "    start_time = datetime.time(0,0)\n",
    "    end_time = datetime.time(23,59)\n",
    "\n",
    "    #Filtered: by date + time\n",
    "    filtered_df = df[\n",
    "        (df['current_time'].dt.date >= start_date.date()) &\n",
    "        (df['current_time'].dt.date <= end_date.date()) &\n",
    "        (df['current_time'].dt.time >= start_time) &\n",
    "        (df['current_time'].dt.time <= end_time)\n",
    "    ].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04929cfe",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Ectracting date"
   },
   "outputs": [],
   "source": [
    "    filtered_df['date'] = filtered_df['current_time'].dt.date\n",
    "\n",
    "    group_cols = ['date', 'close_technician', 'station_name:', 'sfg/top/retest', 'pl', 'cause_of_failure']\n",
    "    grouped = filtered_df.groupby(group_cols).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70337354",
   "metadata": {
    "incorrectly_encoded_metadata": "occurrence = returns)",
    "lines_to_next_cell": 1,
    "title": "Filtered where count > 1 (means repeated"
   },
   "outputs": [],
   "source": [
    "    return_events = grouped[grouped['count'] > 1].copy()\n",
    "    return_events.sort_values(by=['date', 'close_technician'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906e2c08",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Display result"
   },
   "outputs": [],
   "source": [
    "    print(\"\\n=== Technician Return Events Summary (With Timestamps) ===\")\n",
    "    if return_events.empty:\n",
    "        print(\"No return visits detected within the specified time range.\")\n",
    "    else:\n",
    "        print(return_events.to_string(index=False))\n",
    "        print(\"===========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d69850f",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Export as CSV"
   },
   "outputs": [],
   "source": [
    "    df.to_csv(\"tableau_cleaned_data.csv\", index=False)\n",
    "    df.to_csv(r\"C:\\Users\\migerovn\\Desktop\\tableau_cleaned_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982240b9",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Conversion timedelta columns to total minutes"
   },
   "outputs": [],
   "source": [
    "    df['technician_sr_time'] = df['technician_sr_time'].dt.total_seconds() / 60\n",
    "    df['ticket_lifetime'] = df['ticket_lifetime'].dt.total_seconds() / 60\n",
    "    df['current_time'] = df['current_time'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "    df['start_time'] = df['start_time'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "    df['end_time'] = df['end_time'].dt.strftime('%Y-%m-%d %H:%M')\n",
    "    df['delay'] = df['delay'].apply(lambda x: x.total_seconds() / 60 if pd.notnull(x) else None)\n",
    "    print(\"----------\")\n",
    "    print(df[['delay']].head(10))\n",
    "    print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18511ce",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Export as CSV"
   },
   "outputs": [],
   "source": [
    "    df.to_csv(\"tableau_cleaned_data.csv\", index=False)\n",
    "    df.to_csv(r\"C:\\Users\\migerovn\\Desktop\\tableau_cleaned_data_1.csv\", index=False)\n",
    "    print(\"----------\")\n",
    "    print(\"Dataset successfully exported as CSV!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8300cb4",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Export to SQLite Database"
   },
   "outputs": [],
   "source": [
    "    try:\n",
    "        conn = sqlite3.connect(\"tableau_data.db\")\n",
    "        df.to_sql(\"tableau_dataset\", conn, if_exists=\"replace\", index=False)\n",
    "        conn.close()\n",
    "        print(\"----------\")\n",
    "        print(\"Dataset successfully exported to SQLite dataset!\")\n",
    "    except Exception as e:\n",
    "        print(\"----------\")\n",
    "        print(f\"ERROR: Failed to export to SQLite - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7d2804",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Define the ETL function"
   },
   "outputs": [],
   "source": [
    "def run_etl():\n",
    "    print(\"Running ETL process...\")\n",
    "    df = load_and_preprocess()\n",
    "    print(\"ETL process completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3001a4",
   "metadata": {
    "title": "Schedule the ETL to run every hour"
   },
   "outputs": [],
   "source": [
    "schedule.every(12).hours.do(run_etl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68e2c45",
   "metadata": {
    "title": "Keep running in a loop"
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(60)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "incorrectly_encoded_metadata,title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
