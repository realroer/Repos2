{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a7accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest.mock import inplace\n",
    "from nt import rename\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, unicodedata\n",
    "from datetime import datetime, timedelta\n",
    "from numpy.ma.extras import column_stack\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79847c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG: assignment the paths\n",
    "TEST_TIME_XLSX = r\"C:\\Users\\..",
    "SERVICE_TICKETS_XLSX = r\"C:\\Users\\..",
    "OUTPUT_ROWLEVEL_CSV = r\"C:\\Users\\..",
    "OUTPUT_CSV = r\"C:\\Users\\.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d40cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTS_SHEET = 0\n",
    "SERVICE_SHEET = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243f2e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names assignment\n",
    "COL_TS = \"TIME STAMP\"\n",
    "COL_PN = \"PN\"\n",
    "COL_SN = \"SN\"\n",
    "COL_SYMPTOM = \"BIN_DESCRIPTION\"\n",
    "COL_TEST_TYPE = \"TESTER_TYPE\"\n",
    "COL_TESTER = \"TESTER\"\n",
    "COL_TEST_SEC = \"Sum of TEST_TIME in SECONDS\"\n",
    "COL_TEST_HHMMSS = \"Sum of TEST_TIME [h]:mm:ss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf71373",
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_HOSTNAME = \"HostName\"\n",
    "COL_STATION_TYPE = \"Station Type\"\n",
    "COL_LOCK = \"LockDate\"\n",
    "COL_UNLOCK = \"UnlockDate\"\n",
    "COL_DURATION = \"Duration\"\n",
    "COL_FAILED_SN = \"FailedSNList\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc28f27a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# 24h window\n",
    "WINDOW_SECONDS = 24*3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41853499",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Helpers\n",
    "def safe_to_datetime(series_or_value):\n",
    "    \"\"\"Coerce to pandas Timestamp with NaT on failure.\"\"\"\n",
    "    return pd.to_datetime(series_or_value, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c66b89",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def coerce_seconds(x):\n",
    "    \"\"\"Ensure numeric seconds. Accepts numbers, 'hh:mm:ss', or day-fraction string\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return 0.0\n",
    "    if isinstance(x,(int, float, np.integer, np.floating)):\n",
    "        return float(x)\n",
    "    if isinstance(x, str):\n",
    "        s=x.strip()\n",
    "        if \":\" in s:\n",
    "            parts=s.split(\":\")\n",
    "            if len(parts)==3:\n",
    "                try:\n",
    "                    h, m, sec = map(float, parts)\n",
    "                    return h*3600+m*60+sec\n",
    "                except Exception:\n",
    "                    pass\n",
    "        # Numeric day-fraction\n",
    "        try:\n",
    "            return float(s)*86400.0\n",
    "        except Exception:\n",
    "            return 0.0\n",
    "    return 0.0\n",
    "def seconds_to_hhmmss(total_seconds: float) -> str:\n",
    "    \"\"\"Render >24h-capable [h]:mm:ss string (no day wrap).\"\"\"\n",
    "    secs = int(round(max(0, total_seconds)))\n",
    "    h=secs // 3600\n",
    "    m=(secs % 3600) // 60\n",
    "    s=secs%60\n",
    "    return f\"{h}:{m:02d}:{s:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af398ea6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def s_strip(s):\n",
    "    return str(s).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e24a8bb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def merge_overlapping(intervals):\n",
    "    \"\"\"Merge overlapping/touching intervals: [(starts_ts, end_ts), ...] -> merged list.\"\"\"\n",
    "    if not intervals:\n",
    "        return []\n",
    "    intervals = sorted(intervals, key=lambda x: x[0])\n",
    "    merged = [intervals[0]]\n",
    "    for st, et in intervals[1:]:\n",
    "        lst_st, lst_et = merged[-1]\n",
    "        if st <= lst_et: #overlap or touch\n",
    "            merged[-1] = (lst_st, max(lst_et, et))\n",
    "        else:\n",
    "            merged.append((st, et))\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6281ee",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Loading\n",
    "tests = pd.read_excel(TEST_TIME_XLSX, sheet_name=TESTS_SHEET)\n",
    "svc = pd.read_excel(SERVICE_TICKETS_XLSX, sheet_name=SERVICE_SHEET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3234e69",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Force rename column header names\n",
    "def normalize_headers(df):\n",
    "    df.columns = (\n",
    "        df.columns.str.strip()\n",
    "        .str.replace(r\"[/\\\\]\", \"/\", regex=True)\n",
    "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "        .str.lower()\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec12d86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = normalize_headers(tests)\n",
    "svc = normalize_headers(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbf5fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected header mappings\n",
    "tests.rename(\n",
    "    columns={\n",
    "        \"time stamp\": \"TIME STAMP\",\n",
    "        \"pn\": \"PN\",\n",
    "        \"sn\": \"SN\",\n",
    "        \"bin_description\": \"BIN_DESCRIPTION\",\n",
    "        \"test_type\": \"TEST_TYPE\",\n",
    "        \"tester\": \"TESTER\",\n",
    "        \"sum of test_time in seconds\": \"Sum of TEST_TIME in SECONDS\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e45297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.rename(\n",
    "    columns={\n",
    "        \"pn (sfg/sa)\": \"PN\",\n",
    "        \"failedsnlist\": \"SN\",\n",
    "        \"hostname\": \"TESTER\",\n",
    "        \"lockdate\": \"LockDate\",\n",
    "        \"unlockdate\": \"UnlockDate\",\n",
    "        \"duration\": \"Duration\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4253f02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure svc has a numeric seconds column to merge\n",
    "if \"Duration_sec\" not in svc.columns:\n",
    "    if \"Duration\" in svc.columns:\n",
    "        svc[\"Duration_sec\"] = svc[\"Duration\"].apply(coerce_seconds)\n",
    "        print(\"Built svc['Duration_sec'] from svc['Duration']\")\n",
    "    else:\n",
    "        svc[\"Duration_sec\"] = pd.NA\n",
    "        print(\"svc lacks 'Duration' and 'Duration_sec' - created empty seconds column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b110c00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build join (merge) keys (Normalized)\n",
    "tests[\"TIME STAMP\"] = pd.to_datetime(tests[\"TIME STAMP\"], errors=\"coerce\")\n",
    "tests[\"day\"] = tests[\"TIME STAMP\"].dt.floor(\"D\")\n",
    "tests[\"station_name\"] = tests[\"TESTER\"].astype(str).str.strip()\n",
    "tests[\"run_seconds\"] = pd.to_numeric(tests[\"Sum of TEST_TIME in SECONDS\"], errors=\"coerce\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a630d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_daily = (\n",
    "    tests.groupby([\"station_name\", \"day\"], as_index=False)\n",
    "         .agg(run_seconds=(\"run_seconds\", \"sum\"),\n",
    "              test_count=(\"run_seconds\", \"size\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ee66ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secondary prep (Service Tickets) merge key\n",
    "svc[\"station_name\"] = svc[\"TESTER\"].astype(str).str.strip()\n",
    "svc[\"LockDate\"] = pd.to_datetime(svc[\"LockDate\"], errors=\"coerce\")\n",
    "svc[\"UnlockDate\"] = pd.to_datetime(svc[\"UnlockDate\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d723f595",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_valid = svc[\n",
    "    pd.notna(svc[\"LockDate\"]) & pd.notna(svc[\"UnlockDate\"]) & (svc[\"UnlockDate\"] > svc[\"LockDate\"])\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b7e664",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for _, r in svc_valid.iterrows():\n",
    "    st, et, stn = r[\"LockDate\"], r[\"UnlockDate\"], r[\"station_name\"]\n",
    "    d = st.normalize()\n",
    "    while d <= et.normalize():\n",
    "        day_start = pd.Timestamp.combine(d.date(), datetime.min.time())\n",
    "        day_end = day_start + timedelta(days=1)\n",
    "        s = max(st, day_start)\n",
    "        e = min(et, day_end)\n",
    "        if e > s:\n",
    "            rows.append({\"station_name\": stn, \"day\": d, \"start\": s, \"end\": e})\n",
    "        d += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde232a0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "svc_day = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9cf8d0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def merge_overlapping(intervals):\n",
    "    if not intervals:\n",
    "        return []\n",
    "    intervals = sorted(intervals, key=lambda t: t[0])\n",
    "    merged = [intervals[0]]\n",
    "    for s, e in intervals[1:]:\n",
    "        ls, le = merged[-1]\n",
    "        if s <= le:\n",
    "            merged[-1] = (ls, max(le, e))\n",
    "        else:\n",
    "            merged.append((s, e))\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c787346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_daily_rows = []\n",
    "for (stn, day), g in svc_day.groupby([\"station_name\", \"day\"]):\n",
    "    merged_int = merge_overlapping(list(zip(g[\"start\"], g[\"end\"])))\n",
    "    secs = sum((e - s).total_seconds() for s, e in merged_int)\n",
    "    svc_daily_rows.append({\"station_name\": stn, \"day\": day, \"service_seconds\": secs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1840bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_daily = pd.DataFrame(svc_daily_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331229f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary calc\n",
    "summary = pd.merge(run_daily, svc_daily, on=[\"station_name\", \"day\"], how=\"left\")\n",
    "summary[\"service_seconds\"] = summary[\"service_seconds\"].fillna(0.0)\n",
    "summary[\"window_seconds\"] = float(WINDOW_SECONDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c405464d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "summary[\"uptime_pct\"] = (summary[\"run_seconds\"] / summary[\"window_seconds\"]).clip(0, 1)\n",
    "summary[\"service_pct\"] = (summary[\"service_seconds\"] / summary[\"window_seconds\"]).clip(lower=0)\n",
    "summary[\"idle_seconds\"] = (\n",
    "    summary[\"window_seconds\"] - summary[\"run_seconds\"] - summary[\"service_seconds\"]\n",
    ").clip(lower=0)\n",
    "summary[\"idle_pct\"] = (summary[\"idle_seconds\"] / summary[\"window_seconds\"]).clip(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d468ad",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def seconds_to_hhmmss(x):\n",
    "    x = 0 if pd.isna(x) else float(x)\n",
    "    s = int(round(max(0, x)))\n",
    "    h, r = divmod(s, 3600)\n",
    "    m, sec = divmod(r, 60)\n",
    "    return f\"{h}:{m:02d}:{sec:02d}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66131f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary[\"run_hhmmss\"] = summary[\"run_seconds\"].apply(seconds_to_hhmmss)\n",
    "summary[\"service_hhmmss\"] = summary[\"service_seconds\"].apply(seconds_to_hhmmss)\n",
    "summary[\"idle_hhmmss\"] = summary[\"idle_seconds\"].apply(seconds_to_hhmmss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f09586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back extra columns\n",
    "extra_cols = tests[[\"station_name\", \"day\", \"PN\", \"SN\", \"BIN_DESCRIPTION\", \"TEST_TYPE\"]].drop_duplicates()\n",
    "summary = pd.merge(summary, extra_cols, on=[\"station_name\", \"day\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2160898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort and save\n",
    "summary.sort_values([\"station_name\", \"day\"], inplace=True)\n",
    "summary.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"[SUMMARY SAVED] {OUTPUT_CSV} rows={len(summary)}\")\n",
    "print(summary.head(10))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

